# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
#### Design and contrast matrices ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
mp <- x[sample(x=1:100, size=100, replace=T)]
mp <- x[sample(x=1:100, size=100, replace=T)]
mp <- x[sample(x=1:100, size=100, replace=T)]
mp <- x[sample(x=1:100, size=100, replace=T)]
tmp <- x[sample(x=1:100, size=100, replace=T)]
tmp <- x[sample(x=1:100, size=100, replace=T)]
tmp <- x[sample(x=1:100, size=100, replace=T)]
tmp <- x[sample(x=1:100, size=100, replace=T)]
tmp <- x[sample(x=1:100, size=100, replace=T)]
runif(5, min=0, max=1) # Function for pseudorandom numbers, generates n numbers where the next number is dependent on the previous one (not truly random)
set.seed() # Sets the intial number (seed) which the runif() function depends on
#### Histogram of random numbers ####
hist(runif(100))
hist(runif(10000))
#### Normal distribution
# the larger the sample size, the more "normal" the curve
rnorm(100) # Generates n numbers dependent on the normal distribution curve
# Probability density function of the normal distribution
plot(density(rnorm(100))) # Normal distribution PDF, alternatively dnorm(100)
# Compare stochasticity (estimated vs. theoretical PDF)
lines(seq(from=-4, to=4, length=1000),
dnorm(seq(from=-4, to=4, length=1000)),
col=2)
#### Estimating the mean of a distribution ####
mu <- 0 # theoretical mean
sd <- 1
x <- rnorm(100, mean=mu, sd=sd)
m.est <- mean(x) # estimated mean
## standard error of the mean
# var(X1 + X2 + X3) = var(X1) + var(X2) + var(X3)
#var(kX) = k^2 * var(X), therefore...
se <- sd / sqrt(100)
# Estimating the standard error
N <- 1000
mean.vector <- numeric(N) # generates a vector of N elements
# Obtain the mean of normally distributed samples over N experimental runs
for (i in 1:N) {
tmp <- rnorm(100, mean=mu, sd=sd)
mean.vector[i] <- mean(tmp)
}
mean(mean.vector) # UNBIASEDNESS - the larger the no, of experimental runs, the mean tends to mu
# Larger sample size = smaller variability
plot(density(mean.vector))
sd(mean.vector) # the larger the sample size, the closer the sd tends to the theoretical value
## However, we need to know our observations are coming from a normal distribution with the corresponding parameters - hard to know if this is true in practice
#### BOOTSTRAP APPROACH ####
# Allows the estimation of standard error, even for very complex models
# Does not make any assumptions about the data!
## Bootstrap sample - set of samples from the original data WITH REPLACEMENT
boot.s <- sample(x=1:100, size=100, replace=T) # generates a bootstrap sample of the INDEXES of 100 samples, WITH REPLACEMENT (replace is F by default)
# to obtain the actual sample values, do x[sample(x=1:100, size=100, replace=T)]
table(boot.s) # see frequencies of each occurrence
# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
max(bootstr.sd.vector)
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
#### Linear modeling ####
runif(5, min=0, max=1) # Function for pseudorandom numbers, generates n numbers where the next number is dependent on the previous one (not truly random)
set.seed() # Sets the intial number (seed) which the runif() function depends on
#### Histogram of random numbers ####
hist(runif(100))
hist(runif(10000))
#### Normal distribution
# the larger the sample size, the more "normal" the curve
rnorm(100) # Generates n numbers dependent on the normal distribution curve
# Probability density function of the normal distribution
plot(density(rnorm(100))) # Normal distribution PDF, alternatively dnorm(100)
# Compare stochasticity (estimated vs. theoretical PDF)
lines(seq(from=-4, to=4, length=1000),
dnorm(seq(from=-4, to=4, length=1000)),
col=2)
#### Estimating the mean of a distribution ####
mu <- 0 # theoretical mean
sd <- 1
x <- rnorm(100, mean=mu, sd=sd)
m.est <- mean(x) # estimated mean
## standard error of the mean
# var(X1 + X2 + X3) = var(X1) + var(X2) + var(X3)
#var(kX) = k^2 * var(X), therefore...
se <- sd / sqrt(100)
# Estimating the standard error
N <- 1000
mean.vector <- numeric(N) # generates a vector of N elements
# Obtain the mean of normally distributed samples over N experimental runs
for (i in 1:N) {
tmp <- rnorm(100, mean=mu, sd=sd)
mean.vector[i] <- mean(tmp)
}
mean(mean.vector) # UNBIASEDNESS - the larger the no, of experimental runs, the mean tends to mu
# Larger sample size = smaller variability
plot(density(mean.vector))
sd(mean.vector) # the larger the sample size, the closer the sd tends to the theoretical value
## However, we need to know our observations are coming from a normal distribution with the corresponding parameters - hard to know if this is true in practice
#### BOOTSTRAP APPROACH ####
# Allows the estimation of standard error, even for very complex models
# Does not make any assumptions about the data!
## Bootstrap sample - set of samples from the original data WITH REPLACEMENT
boot.s <- sample(x=1:100, size=100, replace=T) # generates a bootstrap sample of the INDEXES of 100 samples, WITH REPLACEMENT (replace is F by default)
# to obtain the actual sample values, do x[sample(x=1:100, size=100, replace=T)]
table(boot.s) # see frequencies of each occurrence
# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
plot(density(bootstr.sd.vector))
sd(bootstr.sd.vector) # computing the standard error
#### Linear modeling ####
runif(5, min=0, max=1) # Function for pseudorandom numbers, generates n numbers where the next number is dependent on the previous one (not truly random)
set.seed() # Sets the intial number (seed) which the runif() function depends on
#### Histogram of random numbers ####
hist(runif(100))
hist(runif(10000))
#### Normal distribution
# the larger the sample size, the more "normal" the curve
rnorm(100) # Generates n numbers dependent on the normal distribution curve
# Probability density function of the normal distribution
plot(density(rnorm(100))) # Normal distribution PDF, alternatively dnorm(100)
# Compare stochasticity (estimated vs. theoretical PDF)
lines(seq(from=-4, to=4, length=1000),
dnorm(seq(from=-4, to=4, length=1000)),
col=2)
#### Estimating the mean of a distribution ####
mu <- 0 # theoretical mean
sd <- 1
x <- rnorm(100, mean=mu, sd=sd)
m.est <- mean(x) # estimated mean
## standard error of the mean
# var(X1 + X2 + X3) = var(X1) + var(X2) + var(X3)
#var(kX) = k^2 * var(X), therefore...
se <- sd / sqrt(100)
# Estimating the standard error
N <- 1000
mean.vector <- numeric(N) # generates a vector of N elements
# Obtain the mean of normally distributed samples over N experimental runs
for (i in 1:N) {
tmp <- rnorm(100, mean=mu, sd=sd)
mean.vector[i] <- mean(tmp)
}
mean(mean.vector) # UNBIASEDNESS - the larger the no, of experimental runs, the mean tends to mu
# Larger sample size = smaller variability
plot(density(mean.vector))
sd(mean.vector) # the larger the sample size, the closer the sd tends to the theoretical value
## However, we need to know our observations are coming from a normal distribution with the corresponding parameters - hard to know if this is true in practice
#### BOOTSTRAP APPROACH ####
# Allows the estimation of standard error, even for very complex models
# Does not make any assumptions about the data!
## Bootstrap sample - set of samples from the original data WITH REPLACEMENT
boot.s <- sample(x=1:100, size=100, replace=T) # generates a bootstrap sample of the INDEXES of 100 samples, WITH REPLACEMENT (replace is F by default)
# to obtain the actual sample values, do x[sample(x=1:100, size=100, replace=T)]
table(boot.s) # see frequencies of each occurrence
# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
#### Linear Modeling ####
runif(5, min=0, max=1) # Function for pseudorandom numbers, generates n numbers where the next number is dependent on the previous one (not truly random)
set.seed() # Sets the intial number (seed) which the runif() function depends on
#### Histogram of random numbers ####
hist(runif(100))
hist(runif(10000))
#### Normal distribution
# the larger the sample size, the more "normal" the curve
rnorm(100) # Generates n numbers dependent on the normal distribution curve
# Probability density function of the normal distribution
plot(density(rnorm(100))) # Normal distribution PDF, alternatively dnorm(100)
# Compare stochasticity (estimated vs. theoretical PDF)
lines(seq(from=-4, to=4, length=1000),
dnorm(seq(from=-4, to=4, length=1000)),
col=2)
#### Estimating the mean of a distribution ####
mu <- 0 # theoretical mean
sd <- 1
x <- rnorm(100, mean=mu, sd=sd)
m.est <- mean(x) # estimated mean
## standard error of the mean
# var(X1 + X2 + X3) = var(X1) + var(X2) + var(X3)
#var(kX) = k^2 * var(X), therefore...
se <- sd / sqrt(100)
# Estimating the standard error
N <- 1000
mean.vector <- numeric(N) # generates a vector of N elements
# Obtain the mean of normally distributed samples over N experimental runs
for (i in 1:N) {
tmp <- rnorm(100, mean=mu, sd=sd)
mean.vector[i] <- mean(tmp)
}
mean(mean.vector) # UNBIASEDNESS - the larger the no, of experimental runs, the mean tends to mu
# Larger sample size = smaller variability
plot(density(mean.vector))
sd(mean.vector) # the larger the sample size, the closer the sd tends to the theoretical value
## However, we need to know our observations are coming from a normal distribution with the corresponding parameters - hard to know if this is true in practice
#### BOOTSTRAP APPROACH ####
# Allows the estimation of standard error, even for very complex models
# Does not make any assumptions about the data!
## Bootstrap sample - set of samples from the original data WITH REPLACEMENT
boot.s <- sample(x=1:100, size=100, replace=T) # generates a bootstrap sample of the INDEXES of 100 samples, WITH REPLACEMENT (replace is F by default)
# to obtain the actual sample values, do x[sample(x=1:100, size=100, replace=T)]
table(boot.s) # see frequencies of each occurrence
# Over many (N) bootstrap samples...
N <- 1000
bootstr.mean.vector <- numeric(N)
for (i in 1:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.mean.vector[i] <- mean(tmp)
}
mean(bootstr.mean.vector)
sd(bootstr.mean.vector)
plot(density(bootstr.mean.vector))
lines(density(mean.vector), col=2)
#### EXERCISE: Estimating standard deviation by the bootstrap approach ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- 1
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
#### Linear Modeling ####
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
model.matrix(~er) # gene
model.matrix(~er)
model.matrix(~er + dose)
model.matrix(~er * dose)
modeling drug trial results
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
# generating a design matrix of ~independent variables
# syntax: dependent~independent variables
model.matrix(~er) # estrogen effect only
model.matrix(~er + dose) # estrogen and dose effect, without interaction
X <- model.matrix(~er * dose) # estrogen and dose effect, with interaction
beta <- x(beta0, beta.er, beta.dose) # vector of parameters (must match order in design matrix!)
Y <- X %*% beta # syntax: %*% - matrix multiplication
plot(dose, Y)
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
# generating a design matrix of ~independent variables
# syntax: dependent~independent variables
model.matrix(~er) # estrogen effect only
model.matrix(~er + dose) # estrogen and dose effect, without interaction
X <- model.matrix(~er * dose) # estrogen and dose effect, with interaction
beta <- c(beta0, beta.er, beta.dose) # vector of parameters (must match order in design matrix!)
Y <- X %*% beta # syntax: %*% - matrix multiplication
plot(dose, Y)
N <- 80
dose <- rep(c(37, 52, 65, 89, 24, 19, 54, 67), 10) # repeat 10 times
er <- rep(c("+", "-"), c(40, 40)) # set the no. of times each value in the vector is repeated, corresponding to the index of the second arg
table(er, dose)
beta0 <- 3 # baseline with no estrogen
beta.er <- 2 # baseline with estrogen
beta.dose <- 0.1 # each unit of dose increases expression by 0.1
## Design matrix
# generating a design matrix of ~independent variables
# syntax: dependent~independent variables
model.matrix(~er) # estrogen effect only
X <- model.matrix(~er + dose) # estrogen and dose effect, without interaction
model.matrix(~er * dose) # estrogen and dose effect, with interaction
beta <- c(beta0, beta.er, beta.dose) # vector of parameters (must match order in design matrix!)
Y <- X %*% beta # syntax: %*% - matrix multiplication
plot(dose, Y)
e <- rnorm(80, mean=0, sd=1)
Y.observed <- Y + e
plot(dose, Y.observed, col=as.numeric(factor(er)))
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- sd(tmp)
}
# Comparing sds from the bootstrap approach to the normal distribution estimator
mean(bootstr.sd.vector)
sd(bootstr.sd.vector) # computing the standard error
plot(density(bootstr.sd.vector))
N <- 1000
bootstr.sd.vector <- numeric(N)
for (i in i:N) {
tmp <- x[sample(x=1:100, size=100, replace=T)]
bootstr.sd.vector[i] <- 1
}
# BiocManager is needed to install Bioconductor packages
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# Install eisaR
BiocManager::install("eisaR")
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
txdbFile
clear all
clear
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"),
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"),
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"),
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb")
BiocManager::available("EnsDb"))
pkgs <- c(BiocManager::available("TxDb"), BiocManager::available("EnsDb"))
BiocManager::install("annotationDbi")
2
BiocManager::install("AnnotationDbi")
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
txdb <- AnnotationDbi::loadDb(txdbFile)
#### Packages ####
library(eisaR)
# Load TxDb object
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
BiocManager::install("eisaR")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# Install eisaR
BiocManager::install("eisaR")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# Install eisaR
BiocManager::install("eisaR")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
# Install eisaR
BiocManager::install("eisaR")
#### Packages ####
library(eisaR)
# Load TxDb object
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
BiocManager::install("GenomicFeatures")
#### Packages ####
library(eisaR)
# Load TxDb object
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
regS <- getRegionsFromTxDb(txdb = txdb, strandedData = TRUE)
regU <- getRegionsFromTxDb(txdb = txdb, strandedData = FALSE)
regS
lengths(regS)
lengths(regU)
regS$exons
getwd()
setwd("/Users/Pomato/mrc")
getwd()
BiocManager::install("QuasR")
library(QuasR) # QuasR package for indexing and aligning short reads
# Copy sample data from package into current directory
file.copy(system.file(package = "QuasR", "extdata"), ".", recursive = TRUE)
setwd("/Users/Pomato/mrc/eisar_tutorial")
# Tutorial: https://bioconductor.org/packages/release/bioc/vignettes/eisaR/inst/doc/eisaR.html
# Documentation: https://bioconductor.org/packages/release/bioc/manuals/eisaR/man/eisaR.pdf
#### Preparing the annotation ####
library(eisaR)
# Load TxDb object
txdbFile <- system.file("extdata", "hg19sub.sqlite", package = "eisaR")
txdb <- AnnotationDbi::loadDb(txdbFile)
# Extract filtered exonic and gene body regions
regS <- getRegionsFromTxDb(txdb = txdb, strandedData = TRUE)
regU <- getRegionsFromTxDb(txdb = txdb, strandedData = FALSE)
lengths(regS)
lengths(regU)
regS$exons
# Exporting to .gtf files
library(rtracklayer)
export(regS$exons, "hg19sub_exons_stranded.gtf")
export(regS$genebodies, "hg19sub_genebodies_stranded.gtf")
#### Quantify RNA-seq alignments in exons and introns
library(QuasR) # QuasR package for indexing and aligning short reads
# Copy sample data from package into current directory
file.copy(system.file(package = "QuasR", "extdata"), ".", recursive = TRUE)
proj <- qAlign(sampleFile = "extdata/samples_rna_single.txt",
genome = "extdata/hg19sub.fa",
aligner = "Rhisat2", splicedAlignment = TRUE)
alignmentStats(proj)
proj <- qAlign(sampleFile = "extdata/samples_rna_single.txt",
genome = "extdata/hg19sub.fa",
aligner = "Rhisat2", splicedAlignment = TRUE)
alignmentStats(proj)
proj <- qAlign(sampleFile = "extdata/samples_rna_single.txt",
genome = "extdata/hg19sub.fa",
aligner = "Rhisat2", splicedAlignment = TRUE)
alignmentStats(proj)
proj <- qAlign(sampleFile = "extdata/samples_rna_single.txt",
genome = "extdata/hg19sub.fa",
aligner = "Rhisat2", splicedAlignment = TRUE)
alignmentStats(proj)
